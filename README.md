# E-SAGE: Explainability-based Defense Against Backdoor Attacks on Graph Neural Networks
Our method is implemented based on the [[UGBA]](https://github.com/ventr1c/UGBA) framework. To reproduce our work, you also need to install Pytorch from [[source]](https://github.com/pytorch/pytorch) to get the  explainability component.
You can also install only relevant packages, which will not conflict with existing environments.
# UGBA: Unnoticeable Backdoor Attack on Graph Neural Networks
An official PyTorch implementation of "Unnoticeable Backdoor Attack on Graph Neural Networks" (WWW 2023). [[paper]](https://arxiv.org/abs/2303.01263) If you find this repo to be useful, please cite our paper. Thank you.
```
@inproceedings{dai2023unnoticeable,
  title={Unnoticeable Backdoor Attacks on Graph Neural Networks},
  author={Dai, Enyan and Lin, Minhua and Zhang, Xiang and Wang, Suhang},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={2263--2273},
  year={2023}
}
```
